{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66a92b9-142d-4c57-87ce-b61c4c74397c",
   "metadata": {},
   "source": [
    "# Decision Tree in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b42dd1-ad8c-4743-a9c6-2373a739bd14",
   "metadata": {},
   "source": [
    "## 1. Introduction to Decision Trees\n",
    "A Decision Tree is a supervised learning algorithm used for both classification and regression tasks. It models decisions and their possible consequences in a tree-like structure, comprising nodes, branches, and leaves. Each internal node represents a \"test\" on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label or a continuous value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb7279-c28d-4787-bc19-5262498d62a0",
   "metadata": {},
   "source": [
    "![Alt Text](Decision_Tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866d7665-154d-46ad-b392-287b2ffca7ed",
   "metadata": {},
   "source": [
    "## 2. Terminologies\n",
    "\n",
    "- **Root Node**: The topmost node in a decision tree, representing the entire dataset.\n",
    "- **Internal Nodes**: Nodes that represent decision points based on the attributes of the data.\n",
    "- **Branches**: The connections between nodes, representing the outcome of a decision or test.\n",
    "- **Leaf Nodes**: The terminal nodes that represent the final output or class label.\n",
    "- **Splitting**: The process of dividing a node into two or more sub-nodes based on certain criteria.\n",
    "- **Pruning**: The process of removing sub-nodes from a decision tree to reduce its complexity and improve generalization.\n",
    "- **Impurity**: A measure of the disorder or uncertainty in a dataset (e.g., Gini impurity, entropy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87d8941-5e66-4270-b61b-1fbe150c8b37",
   "metadata": {},
   "source": [
    "## 3. How Decision Tree is Formed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b0f411-8b24-4429-a253-638732f3d127",
   "metadata": {},
   "source": [
    "### Step-by-Step Process\n",
    "\n",
    "1. **Selecting the Best Attribute**: The process begins with selecting the best attribute to split the dataset. This selection is based on criteria such as Gini impurity, Information Gain (using entropy), or Mean Squared Error (for regression tasks).\n",
    "\n",
    "2. **Splitting the Data**: Once the best attribute is selected, the data is split into subsets based on the attributeâ€™s possible values.\n",
    "\n",
    "3. **Recursive Partitioning**: This process of selecting the best attribute and splitting the data continues recursively for each subset until a stopping condition is met (e.g., all samples belong to the same class, a maximum tree depth is reached, or no further information gain can be achieved).\n",
    "\n",
    "4. **Assigning Class Labels**: At the leaf nodes, a class label (for classification) or a continuous value (for regression) is assigned based on the majority class or average of the values, respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8f0b3-f0fe-4e13-b336-82a42cd9f179",
   "metadata": {},
   "source": [
    "## 4. Why Decision Tree?\n",
    "\n",
    "- **Easy to Understand and Interpret**: Decision trees are simple to visualize and explain, making them accessible even to non-experts.\n",
    "- **No Need for Data Normalization**: Decision trees do not require feature scaling or normalization.\n",
    "- **Handles Both Numerical and Categorical Data**: Decision trees can work with various types of data without the need for extensive preprocessing.\n",
    "- **Feature Importance**: They provide insights into the importance of different features in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b6e0d-3fa1-4154-8a4b-97a0e0feb803",
   "metadata": {},
   "source": [
    "## 5. Advantages and Disadvantages of Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e409ad-695c-4ead-8cc0-e97f733d49b0",
   "metadata": {},
   "source": [
    "### Advantages\n",
    "\n",
    "- **Easy to Understand and Interpret**:  The tree structure is simple to visualize and explain.\n",
    "- **Handles Both Numerical and Categorical Data**:  Decision trees can work with different types of data.\n",
    "- **No Need for Data Normalization**:  Decision trees do not require feature scaling or normalization.\n",
    "- **Feature Importance**:  Provides insights into the importance of different features.\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "- **Overfitting**: Decision trees can become overly complex and model noise in the data, leading to poor generalization.\n",
    "- **Instability**:  Small changes in the data can result in a completely different tree structure.\n",
    "- **Bias towards Certain Features**: Decision trees can be biased towards features with more levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec63e9c3-0b55-445c-8859-fbcd4bfcf035",
   "metadata": {},
   "source": [
    "## 6. Building a Decision Tree Classification Model: Wine Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b2b2c-1823-4a08-b0c1-e2ba5ae95655",
   "metadata": {},
   "source": [
    "![Alt Text](image_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e617d5-b799-47af-a669-1a4e52ec236b",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9adb069c-6ff3-429b-98d0-5a799bded616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e9fb99-8da0-4e2b-a8c4-22a65dde98ea",
   "metadata": {},
   "source": [
    "### Step 2: Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c8eb48c-5966-4ca6-91a1-7886ff792e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Wine dataset\n",
    "df = pd.read_csv('Titanic-Dataset.csv')\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd8c0574-df2d-460b-9ac4-084ae5272cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30530b41-b801-480f-b713-49ccfef99935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d38339-24e2-4bab-b2f2-5af4721cefa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b20a0fc3-f474-4f0b-b07a-4edd0dc863fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are not needed\n",
    "df = df.drop(columns=['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b798cf77-a976-417d-b1c2-14f9e2456105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Sex         0\n",
       "Age         0\n",
       "Fare        0\n",
       "Embarked    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle missing values\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d75df6ee-3f89-41ec-8e99-d5c9452efa5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Sex         0\n",
       "Age         0\n",
       "Fare        0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['Embarked'])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1f326c-56d9-4e06-b295-08c4c0eb2c36",
   "metadata": {},
   "source": [
    "### Step 3: Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96384f49-a5f2-48de-813b-3deffc741329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.countplot(data=df, x='Survived')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9979613-24ac-42ab-9506-d87d0808126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['Age'].dropna(), kde=True)\n",
    "plt.title('Age Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d68977-741c-4746-8319-685257c7651a",
   "metadata": {},
   "source": [
    "### Step 4: Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd33c9-0493-4127-96de-05000b154239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert categorical variables into numeric\n",
    "label_encoder = LabelEncoder()\n",
    "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
    "df['Embarked'] = label_encoder.fit_transform(df['Embarked'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a4c2f-3f3f-44c1-b94e-869aaf9684cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target variable\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ecc8f-5474-4c8d-a3a5-1e512f126980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4214b09a-8242-417f-8734-a8e0a55bc5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a0b02-2439-41ff-bd35-220740e86e76",
   "metadata": {},
   "source": [
    "### Step 5: Train the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faa5b48-e76c-43da-86ec-b7657accc56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create and train the Decision Tree classifier\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e619931-cbdd-4757-b4c3-7bb34d27fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3a5365-1576-419c-81ae-832ffd09b470",
   "metadata": {},
   "source": [
    "### Step 6: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f68d5-11c5-403a-8f22-f433b95e1084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7cee2b-abdd-47ee-9d40-605c667adf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ef8128-aeb1-4ea2-81ac-f7930a0815a4",
   "metadata": {},
   "source": [
    "### Step 7: Visualize the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be05cf6-b5b2-4c8f-b4a8-1da5ae41b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(model, feature_names=X.columns, class_names=['Not Survived', 'Survived'], filled=True)\n",
    "plt.title('Decision Tree')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184eecd4-7ce5-408d-8423-74146868ec16",
   "metadata": {},
   "source": [
    "### Step 8: Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93de971e-0425-46b3-8fc1-e4bf0eae89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_survival(model, pclass, sex, age, fare, embarked):\n",
    "    # Create a DataFrame for the input data\n",
    "    example_data = pd.DataFrame({\n",
    "        'Pclass': [pclass],\n",
    "        'Sex': [sex],\n",
    "        'Age': [age],\n",
    "        'Fare': [fare],\n",
    "        'Embarked': [embarked]\n",
    "    })\n",
    "    \n",
    "    # Predict survival\n",
    "    example_prediction = model.predict(example_data)\n",
    "    \n",
    "    # Return the result\n",
    "    return 'Survived' if example_prediction[0] == 1 else 'Not Survived'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23db380-6b7e-4cb9-bd7b-33c2b69fa850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of the function\n",
    "result = predict_survival(\n",
    "    model=model,\n",
    "    pclass=3,\n",
    "    sex=1,  # male\n",
    "    age=22,\n",
    "    fare=7.25,\n",
    "    embarked=2  # S\n",
    ")\n",
    "\n",
    "print(f'Predicted survival: {result}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5479f551-d2ff-4cb4-ab5a-2eba1e1de66a",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this notebook, we performed digit classification using the Titanic dataset and a Decision Tree classifier. We explored the dataset, visualized the images, preprocessed the data, trained the model, evaluated its performance, and visualized the predictions. The Decision Tree classifier achieved a reasonable accuracy, and the confusion matrix helped us understand the model's performance across different digits.\n",
    "\n",
    "This step-by-step guide provides a comprehensive introduction to Titanic dataset classification for beginners, covering all essential aspects from data exploration to model evaluation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
